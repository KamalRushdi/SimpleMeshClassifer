{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# vanilla architecture\n",
    "# network architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplePointNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimplePointNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Shared MLP for feature extraction\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for per-point classification\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(1024, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, 1)  # Output per point\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 3, num_points)\n",
    "        x = self.mlp1(x)  # Shape: (batch_size, 1024, num_points)\n",
    "        x = self.mlp2(x)  # Shape: (batch_size, num_classes, num_points)\n",
    "\n",
    "        return x  # Shape: (batch_size, num_classes, num_points)\n",
    "\n"
   ],
   "id": "c1af549a3129f29d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# simple architecture TNet\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "\n",
    "        self.fc3.weight.data.zero_()\n",
    "        self.fc3.bias.data.copy_(torch.eye(k).view(-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(B, self.k, self.k)\n",
    "\n",
    "class SimplePointNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimplePointNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Input T-Net\n",
    "        self.input_transform = TNet(k=3)\n",
    "\n",
    "        # Shared MLP for feature extraction\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for per-point classification\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(1024, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, 1)  # Output per point\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 3, num_points)\n",
    "        B, _, N = x.shape\n",
    "\n",
    "        # Apply input transform\n",
    "        trans = self.input_transform(x)  # (B, 3, 3)\n",
    "        x = torch.bmm(trans, x)          # Apply to point cloud\n",
    "\n",
    "        x = self.mlp1(x)                 # (B, 1024, N)\n",
    "        x = self.mlp2(x)                 # (B, num_classes, N)\n",
    "        return x\n"
   ],
   "id": "65383facce3ce0b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T18:11:12.968843Z",
     "start_time": "2025-03-29T18:11:11.052537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# adding global feature to each point\n",
    "# adding dropout after concatenating global feature to each point\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Shared MLP for feature extraction (split to capture intermediate features)\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        # MLP after concatenating global feature to each point (64 + 1024 = 1088)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(1088, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),  # Increased dropout\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(256, self.num_classes, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (B, 3, N)\n",
    "        B, _, N = x.shape\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 64, N)\n",
    "        point_feat = x                      # Save 64-dim per-point features\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 128, N)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 1024, N)\n",
    "\n",
    "        global_feat = torch.max(x, 2, keepdim=True)[0]  # (B, 1024, 1)\n",
    "        global_feat = global_feat.repeat(1, 1, N)       # (B, 1024, N)\n",
    "\n",
    "        x = torch.cat([point_feat, global_feat], 1)     # (B, 1088, N)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # Extra dropout after concat\n",
    "        x = self.mlp2(x)                                # (B, num_classes, N)\n",
    "        return x\n"
   ],
   "id": "5f4d88b09499e84b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TNet with previous architecture\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "\n",
    "        self.fc3.weight.data.zero_()\n",
    "        self.fc3.bias.data.copy_(torch.eye(k).view(-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(B, self.k, self.k)\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Input T-Net\n",
    "        self.input_transform = TNet(k=3)\n",
    "\n",
    "        # Shared MLP for feature extraction (split to capture intermediate features)\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        # MLP after concatenating global feature to each point (64 + 1024 = 1088)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(1088, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(256, self.num_classes, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (B, 3, N)\n",
    "        B, _, N = x.shape\n",
    "\n",
    "        # Apply input transform\n",
    "        trans = self.input_transform(x)                  # (B, 3, 3)\n",
    "        x = torch.bmm(trans, x)                          # Apply transformation\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))              # (B, 64, N)\n",
    "        point_feat = x                                   # Save 64-dim per-point features\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))              # (B, 128, N)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))              # (B, 1024, N)\n",
    "\n",
    "        global_feat = torch.max(x, 2, keepdim=True)[0]   # (B, 1024, 1)\n",
    "        global_feat = global_feat.repeat(1, 1, N)        # (B, 1024, N)\n",
    "\n",
    "        x = torch.cat([point_feat, global_feat], 1)      # (B, 1088, N)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)  # Extra dropout after concat\n",
    "        x = self.mlp2(x)                                 # (B, num_classes, N)\n",
    "        return x\n"
   ],
   "id": "9e81ab7dd22523cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
